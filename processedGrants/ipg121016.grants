patentno,patpubdate,title,appno,priorpub,priorpubdate,abstract,invs,assignee,xref,filedate,govint,parentcase,childcase,date371,pctpubno
08286490,20121016,Array systems and related methods for structural health monitoring,12638315,20100206080,20100819,"Systems and related methods for structural health monitoring are provided. In this regard, a representative array system includes: a component to be monitored; and an array system mounted to the component, the array system has multiple array components exhibiting spatial periodicity, the array components being operative to produce waves with frequency dependent directional characteristics, which propagate through the component, responsive to simultaneous activation of the array components.","",[Georgia Tech Research Corporation],"This utility application claims the benefit of and priority to U.S. Provisional Application 61/122,917, which was filed on Dec. 16, 2008, and which is incorporated by reference herein in its entirety.",20091215,"This invention was made with support from the U.S. government under grant number: 0800263, awarded by the National Science Foundation. The Government has certain rights in the invention.","","","",""
08287610,20121016,Rapid solar-thermal conversion of biomass to syngas,11847097,20080086946,20080417,"Methods for carrying out high temperature reactions such as biomass pyrolysis or gasification using solar energy. The biomass particles are rapidly heated in a solar thermal entrainment reactor. The residence time of the particles in the reactor can be 5 seconds or less. The biomass particles may be directly or indirectly heated depending on the reactor design. Metal oxide particles can be fed into the reactor concurrently with the biomass particles, allowing carbothermic reduction of the metal oxide particles by biomass pyrolysis products. The reduced metal oxide particles can be reacted with steam to produce hydrogen in a subsequent process step.","","[The Regents of the University of Colorado, a body corporate]","This application claims the benefit of U.S. Provisional Application 60/823,872, filed Aug. 29, 2006, which is hereby incorporated by reference to the extent not inconsistent with the disclosure herein.",20070829,The invention was made with Government support from the National Science Foundation Graduate Research Fellowship program. The United States government may have certain rights in the invention.,"","","",""
08287849,20121016,Biodegradable poly(beta-amino esters) and uses thereof,12507999,20100036084,20100211,"Poly(β-amino esters) prepared from the conjugate addition of bis(secondary amines) or primary amines to a bis(acrylate ester) are described. Methods of preparing these polymers from commercially available starting materials are also provided. These tertiary amine-containing polymers are preferably biodegradable and biocompatible and may be used in a variety of drug delivery systems. Given the poly(amine) nature of these polymers, they are particularly suited for the delivery of polynucleotides. Nanoparticles containing polymer/polynucleotide complexes have been prepared. The inventive polymers may also be used to encapsulate other agents to be delivered. They are particularly useful in delivering labile agents given their ability to buffer the pH of their surroundings.","",[Massachusetts Institute of Technology],"The present application claims priority to provisional applications, U.S. Ser. No. 60/305,337, filed Jul. 13, 2001, and U.S. Ser. No. 60/239,330, filed Oct. 10, 2000, each of which is incorporated herein by reference.",20090723,"This invention was made with Government support under Grant No. ECC9843342, awarded by the National Science Foundation; under Grant No. GM26698 and Grant No. 1 F32 GM20227-01, awarded by the National Institutes of Health; and under Grant No. DAMD 17-99-2-9-001, awarded by the Department of the Army. The Government has certain rights in this invention.",11099886,12507999,"",""
08287914,20121016,Biomimetic hydroxyapatite synthesis,11622927,20070196509,20070823,"A method for preparing nanoscale hydroxyapatite particles by combining an amount of a calcium ion source, which includes calcium acetate, and an amount of a phosphate ion source, wherein the amounts are sufficient to produce nanoscale hydroxyapatite particles and the amounts are combined under ambient conditions to produce the hydroxyapatite particles. Nanoscale hydroxyapatite particles are also presented.","","[Rutgers, The State University of New Jersey]","This application claims priority to U.S. Provisional Application Ser. No. 60/758,207, which was filed on Jan. 12, 2006, the disclosure of which is incorporated herein by reference.",20070112,The U.S. Government has a paid-up license in this invention and the right in limited circumstances to require the patent owner to license others on reasonable terms as provided for by the terms of grant DGE033196 awarded by the National Science Foundation.,"","","",""
08288497,20121016,Synthesis of poly-(P-aryleneethynylene)s in neat water under aerobic conditions,13173395,20110257356,20111020,Provided are ethyne synthons comprising boron and related methods. Also provided are related water-soluble arylethynylene polymers capable of being synthesized in neat water under aerobic conditions.,"",[The Trustees Of The University of Pennsylvania],"This application is a continuation U.S. application Ser. No. 12/394,146, filed Feb. 27, 2009 and claims the benefit of U.S. Application 61/031,831, filed on Feb. 27, 2008, the entirety of each application is incorporated by reference herein.",20110630,"The government may have certain rights in this invention. This work was supported by a grant from the Division of Chemical Sciences, Office of Basic Energy Research, U.S. Department of Energy (DE-FGO2-02ER15299). Additional support was provided by MRSEC (DMR-00-79909) and NSEC (DMR-0425780) Programs of the National Science Foundation.",12394146,13173395,"",""
08288508,20121016,Universal grignard	 metathesis polymerization,11849229,20080146754,20080619,"Universal Grignard Metathesis (GRIM) reactions which provide access to conjugated polymers by GRIM methods. A method comprising: providing an unsaturated ring compound comprising at least two halogen ring substituents, providing an organomagnesium reagent comprising an organomagnesium component and a metal activation agent, combining the unsaturated ring compound with the reagent to form a second compound by metal-halogen exchange, wherein the metal activation agent activates the metal-halogen exchange, coupling the second compound to itself in an oligomerization or polymerization reaction. Metal activation agent can be lithium chloride. The process is commercially attractive and can be executed in good yields. Polyfluorenes, polypyrroles, and polythiophenes can be prepared for use in OLED, PLED, photovoltaic, transistor, antistatic coatings, and sensor applications.","",[Carnegie Mellon University],"This application claims the benefit of U.S. Provisional Application Ser. No. 60/841,548, filed Sep. 1, 2006, which is incorporated herein by reference in its entirety.",20070831,"One or more embodiments described herein were developed with federal funding under grant numbers National Science Foundation, CHE 0415369.","","","",""
08288719,20121016,"Analytical instruments, assemblies, and methods",12005805,"","","Analytical instruments configured to perform atmospheric pressure ionization are provided that are less than 50 kgs in total weight and/or less than 1 min total volume. Mass analysis instruments are provided that can include an interface vacuum structure operatively coupled between an ionization source and a vacuum region housing a detector. Mass analysis instruments are also provided that can include an ionization source coupled to an analysis region via an interface vacuum structure, with at least two independent vacuum components.","","[Griffin Analytical Technologies, LLC]","This application claims priority to U.S. provisional patent application 60/877,965 which was filed Dec. 29, 2006, entitled &#x201C;Analytical Instruments, Assemblies, and Methods&#x201D;, the entirety of which is incorporated by reference herein.",20071228,This invention was made with Government support under SBIR Phase-II Grant 0450512 awarded by the National Science Foundation. The Government has certain rights in the invention.,"","","",""
08289519,20121016,"Surface plasmon resonance (SRP) microscopy systems, method of fabrication thereof, and methods of use thereof",12077771,20120154814,20120621,"Surface plasmon resonance (SPR) microscopy systems, methods of making SPR microscopy systems, methods of measuring and detecting the presence of one or more compounds present in a sample using the SPR microscopy system, and the like, are disclosed. In an embodiment, a surface plasmon resonance (SPR) microscopy system can include an integrated microfluidic chip that includes a plurality of layers, an SPR imaging system, and a pressure manifold to actuate flow control components in the integrated microfluidic chip.","",[Stanford University],"This application claims priority to U.S. provisional application entitled, &#x201C;SURFACE PLASMON RESONANCE (SPR) MICROSCOPY SYSTEMS, METHOD OF FABRICATION THEREOF, AND METHODS OF USE THEREOF,&#x201D; having Ser. No. 60/919,292, filed on Mar. 21, 2007, which is entirely incorporated herein by reference.",20080321,This invention was made with Government support under contract 0411641 awarded by the National Science Foundation. The Government has certain rights in this invention.,"","","",""
08290037,20121016,"Feedback assisted transmission of multiple description, forward error correction coded, streams in a peer-to-peer video system",12145675,20090034614,20090205,"MD-FEC is considered an efficient way to generate a large number of descriptions. However, typically, MD-FEC introduces significant redundancy across streams. MD-FEC encoded streams (descriptions) are adapted based on feedback. Specifically, the bits sent in each description by a supplying peer are adapted based on the number of available descriptions in its receiving peer. The adaptive delivery eliminates unnecessary bits in the original MD-FEC streams (descriptions), and significantly reduces the consumed uplink bandwidth at supplying peers. The saved bandwidth can be used to accommodate more video sessions or for other applications.","",[Polytechnic Institute of New York University],"Benefit is claimed to the filing date of U.S. Provisional Patent Application Ser. No. 60/937,808 (&#x201C;the '808 provisional&#x201D;), titled &#x201C;FEEDBACK ASSISTED REDUNDANCY-FREE TRANSMISSION OF MD-FEC STREAMS IN P2P VIDEO,&#x201D; filed on Jun. 28, 2007 and listing Zhengye LIU, Shivendra S. PANWAR, Keith W. ROSS, Yanming SHEN and Yao WANG as inventors. The '808 provisional is incorporated herein by reference. However, the scope of the claimed invention is not limited by any requirements of any specific embodiments described in the '808 provisional.",20080625,"The United States Government may have certain rights in this invention pursuant to a grant awarded by the National Science Foundation. Specifically, the United States Government has a paid-up license in this invention and the right in limited circumstances to require the patent owner to license others on reasonable terms as provided for by the terms of Contract or Grant No. 0435228 awarded by the National Science Foundation.","","","",""
08291034,20121016,Centralized adaptive network memory engine,13073459,"","","There is a constant battle to break even between continuing improvements in DRAM capacities and the growing memory demands of large-memory high-performance applications. Performance of such applications degrades quickly once the system hits the physical memory limit and starts swapping to the local disk. We present the design, implementation and evaluation of Anemone—an Adaptive Network Memory Engine—that virtualizes the collective unused memory of multiple machines across a gigabit Ethernet LAN, without requiring any modifications to the either the large memory applications or the Linux kernel. We have implemented a working prototype of Anemone and evaluated it using real-world unmodified applications such as ray-tracing and large in-memory sorting. Our results with the Anemone prototype show that unmodified single-process applications execute 2 to 3 times faster and multiple concurrent processes execute 6 to 7.7 times faster, when compared to disk based paging. The Anemone prototype reduces page-fault latencies by a factor of 19.6—from an average of 9.8 ms with disk based paging to 500 μs with Anemone. Most importantly, Anemone provides a virtualized low-latency access to potentially “unlimited” network memory resources.","",[The Research Foundation of State University of New York],"The present application claims benefit of priority from U.S. patent application Ser. No. 11/957,411, filed Dec. 15, 2007, which claims benefit of priority from U.S. Provisional Patent Application No. 60/870,320, filed Dec. 15, 2006, the entirety of which are expressly incorporated herein by reference.1 IntroductionRapid improvements in DRAM capacities have been unable to keep up with the unprecedented the growth in memory demands of applications, such as multimedia/graphics processing, high resolution volumetric rendering, weather prediction, large-scale simulations, and large databases. The issue is not whether one can provide enough DRAM to satisfy these modern memory-hungry applications; rather, provide more memory and they'll use it all up and ask for even more. Simply buying more memory to plug into a single machine is neither sustainable nor economical for most users because (1) the price per byte of DRAM within a single node increases non-linearly and rapidly, (2) memory bank limitations within commodity nodes prevent unrestricted scaling and (3) investment in specialized large memory hardware is prohibitively expensive and such technology quickly becomes obsolete.In this constant battle to break-even, it does not take very long for large memory applications to hit the physical memory limit and start swapping (or paging) to physical disk, which in turn throttles their performance. At the same time, it is often the case that while memory resources in one machine might be heavily loaded, large amounts of memory in other machines in a high-speed LAN might remain idle or under-utilized. In typical commodity clusters, one often sees a mixed batch of applications of which some have very high memory demands, while most have only low or moderate demands. Consequently, instead of paging directly to a slow local disk, one could significantly reduce access latencies by first paging over a high-speed LAN to the unused memory of remote machines and then turn to disk-based paging only as the last resort after exhausting the available remote memory. Remote memory access can be viewed as another level in the traditional memory hierarchy which fills the widening performance gap between very low latency access to main memory and high latency access to local disk.Recent years have also seen a phenomenal rise in affordable gigabit Ethernet LANs that provide low latency, support for jumbo frames (packet sizes greater than 1500 bytes), and offer attractive cost-to-performance ratios. An interesting question naturally follows from the above discussion: Can we transparently virtualize (or pool together) the collective unused memory of commodity nodes across a high-speed LAN and enable unmodified large memory applications to avoid the disk access bottleneck by using this collective memory resource? Prior efforts [6, 11, 10, 17, 19, 12, 20, 23] to address this problem have either relied upon expensive interconnect hardware (ATM/Myrinet/Infiniband) or used bandwidth limited 10/100 Mbps networks that are far too slow to provide meaningful application speedups. In addition, extensive changes were often required either to the large memory applications or the end-host operating system. Note that the above research question of transparent remote memory access is different from the research on Software Distributed Shared Memory (DSM) [9] systems that permits nodes in a network to behave as if they were shared memory multiprocessors, often requiring use of customized application programming interfaces.Experiences in the design, implementation and evaluation of the Adaptive Network Memory Engine (Anemone) system are described. Anemone virtualizes the collective unused memory resources across nodes in a commodity gigabit Ethernet LAN and allows unmodified memory-hungry applications to transparently benefit from low-overhead access to potentially &#x201C;unlimited&#x201D; remote memory resources. The Anemone system makes the following specific contributions. (1) Anemone presents a unified virtual interface for each memory client to access an aggregated pool of remote memory. (2) Any application can benefit from Anemone without requiring any code changes, recompilation, or relinking. Anemone system is implemented in pluggable kernel modules and does not require any changes to the core operating system. (3) Anemone is designed to automatically adapt as the applications' memory requirements change and/or the cluster-wide memory resource availability changes. It effectively isolates the clients from changes in the aggregate memory pool and isolates the memory contributors from changes in client memory requirements. (4) To the best of our knowledge, Anemone system is the first attempt at evaluating the feasibility of remote memory access over commodity gigabit Ethernet with jumbo frame support.Performance evaluations were conducted using two real world unmodified applications&#x2014;ray-tracing and large in memory sorting. Anemone reduces page-fault latencies by a factor of 19.6&#x2014;from an average of 9.8 ms with disk based paging to about 500 &#x3BC;s with Anemone. Anemone speeds up single-process large-memory applications by a factor of 2 to 3 and multiple concurrent large-memory applications by a factor of 6 to 7.7.It is therefore an object to provide a distributed remote memory access system, comprising: (a) at least one client, said client comprising: (1) a cache memory, and (2) a client remote memory access protocol layer, wherein when a memory page is evicted from said cache memory, it is communicated, under control of said client remote memory access protocol layer, destined to a cooperating server through a packet data network, and when said evicted memory page is required, a request is made under control of said client remote memory access protocol layer, destined to the cooperating server, to request and control retrieval of said evicted memory page. The distributed remote memory access system may further comprise (b) at least one server, said server comprising: (1) a server remote memory access protocol layer, (2) a memory contributed for use by a client, and (3) a hash table, storing a location of evicted memory pages from the cooperating client, wherein evicted memory pages received through said packet data network under control of said server remote memory access protocol layer from a memory engine are stored in said memory, and said hash table is updated to store a location of the stored evicted memory page, and requested portions of said evicted memory pages are retrieved from said memory based on said hash table and transmitted through said packet data network under control of said server remote memory access protocol layer. The distributed remote memory access system may comprise (3) a network interface, wherein when a memory page is evicted from said cache memory, it is communicated, under control of said client remote memory access protocol layer, destined to a cooperating server through said network interface, and when said evicted memory page is required, a request is made under control of said client remote memory access protocol layer, destined to the cooperating server, to request and control retrieval of said evicted memory page through said network interface.It is another object to provide a server for a distributed memory system, comprising: (1) a server remote memory access protocol layer; (2) a memory; (3) a hash table, storing a location of evicted memory pages from the cooperating client; and (4) a network interface, wherein evicted memory pages received through said network interface under control of said server remote memory access protocol layer from a memory engine are stored in said memory, and said hash table is updated to store an identification of the location of the stored evicted memory page, and requested portions of said evicted memory pages are retrieved from said memory based on said hash table and transmitted through said network interface under control of said server remote memory access protocol layer.It is a still further object to provide a server for a distributed remote memory access system, in combination with at least one client, said client comprising: (1) a cache memory, and (2) a client remote memory access protocol layer, wherein when a memory page is evicted from said cache memory, it is communicated, under control of said client remote memory access protocol layer, destined to a cooperating server through a packet data network, and when said evicted memory page is required, a request is made under control of said client remote memory access protocol layer, destined to the cooperating server, to request and control retrieval of said evicted memory page.Another object provides a method for operating a distributed memory system, comprising: evicting a memory page from a cache memory of a computing device; communicating, under control of a client remote memory access protocol layer, the memory page to a network system; storing, on a network device, information to identify the at least one cooperating server receiving the evicted memory page; and requesting, under control of the client remote memory access protocol layer, retrieval of the evicted memory page, from the at least one cooperating server identified by the stored identifying information. The method may be embodied in a computer readable software medium for controlling a general purpose processor.",20110328,This invention was made with government support under Grant No. 0509131 awarded by the National Science Foundation. The U.S. Government has certain rights in the invention.,11957411,13073459,"",""
